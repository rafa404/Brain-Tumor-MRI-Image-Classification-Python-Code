{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97f33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ö° Using Apple MPS (Metal GPU) backend\n",
      "üìÇ Train samples: 5710 | Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "üìÇ Test samples : 1309 | Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "üöÄ Using VGG19 Pretrained Backbone\n",
      "\n",
      "üöÄ Training VGG19...\n",
      "[Epoch 01] LR=1.00e-05 | Train Acc=0.7942, Test Acc=0.8472 | Train Loss=0.7466, Test Loss=0.6372 | Test F1=0.8410\n",
      "üíæ New Best Model (by F1): F1=0.8410 at Epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    120\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 121\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    122\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    123\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, time, warnings, logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# =====================\n",
    "# SETTINGS\n",
    "# =====================\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Use MPS (Apple GPU) if available\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    logger.info(\"‚ö° Using Apple MPS (Metal GPU) backend\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    logger.info(\"‚ö†Ô∏è MPS not available, using CPU\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "IMG_SIZE = 224   # VGG models default to 224px input\n",
    "LR = 1e-5\n",
    "PATIENCE = 5     # early stopping\n",
    "\n",
    "TRAIN_DIR = r'/Users/muhammadmuhtasimshahriar/Downloads/archive/Training'\n",
    "TEST_DIR  = r'/Users/muhammadmuhtasimshahriar/Downloads/archive/Testing'\n",
    "\n",
    "# =====================\n",
    "# DATA TRANSFORMS\n",
    "# =====================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# DATASETS & CLASSES\n",
    "# =====================\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "logger.info(f\"üìÇ Train samples: {len(train_dataset)} | Classes: {train_dataset.classes}\")\n",
    "logger.info(f\"üìÇ Test samples : {len(test_dataset)} | Classes: {test_dataset.classes}\")\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# =====================\n",
    "# BALANCED SAMPLER\n",
    "# =====================\n",
    "class_counts = np.bincount(train_dataset.targets)\n",
    "class_weights = 1. / class_counts\n",
    "samples_weight = [class_weights[t] for t in train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# =====================\n",
    "# MODEL: VGG19\n",
    "# =====================\n",
    "logger.info(\"üöÄ Using VGG19 Pretrained Backbone\")\n",
    "model = models.vgg19(weights=\"IMAGENET1K_V1\")\n",
    "in_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Fine-tune all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3, factor=0.3)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# =====================\n",
    "# TRAINING\n",
    "# =====================\n",
    "best_f1, best_acc = 0, 0\n",
    "best_f1_epoch, best_acc_epoch = 0, 0\n",
    "patience_counter, best_epoch = 0, 0\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "train_loss_list, test_loss_list, f1_list = [], [], []\n",
    "\n",
    "start_time = time.time()\n",
    "logger.info(\"\\nüöÄ Training VGG19...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # ---- Eval ----\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_acc = correct / total\n",
    "    test_loss /= len(test_loader)\n",
    "    test_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    # Record history\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    f1_list.append(test_f1)\n",
    "\n",
    "    scheduler.step(test_f1)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    logger.info(f\"[Epoch {epoch+1:02d}] LR={lr:.2e} | \"\n",
    "                f\"Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f} | \"\n",
    "                f\"Train Loss={train_loss:.4f}, Test Loss={test_loss:.4f} | \"\n",
    "                f\"Test F1={test_f1:.4f}\")\n",
    "\n",
    "    # Track best F1\n",
    "    if test_f1 > best_f1:\n",
    "        best_f1 = test_f1\n",
    "        best_f1_epoch = epoch + 1\n",
    "        best_epoch = best_f1_epoch\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_vgg19.pth\")\n",
    "        logger.info(f\"üíæ New Best Model (by F1): F1={best_f1:.4f} at Epoch {best_f1_epoch}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            logger.info(\"‚èπ Early stopping.\")\n",
    "            break\n",
    "\n",
    "    # Track best Accuracy too\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_acc_epoch = epoch + 1\n",
    "\n",
    "elapsed = (time.time()-start_time)/60\n",
    "logger.info(f\"\\n‚è± Training finished in {elapsed:.1f} min. Best F1={best_f1:.4f} at epoch {best_f1_epoch}, Best Acc={best_acc:.4f} at epoch {best_acc_epoch}\")\n",
    "\n",
    "# =====================\n",
    "# LOAD BEST MODEL (by F1)\n",
    "# =====================\n",
    "model.load_state_dict(torch.load(\"best_vgg19.pth\"))\n",
    "model.eval()\n",
    "logger.info(\"üîÑ Loaded best saved VGG19 for final evaluation.\")\n",
    "\n",
    "# =====================\n",
    "# FINAL EVALUATION\n",
    "# =====================\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "final_acc = accuracy_score(y_true, y_pred)\n",
    "final_prec = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "final_rec = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "final_f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "logger.info(\"\\nüìä FINAL PERFORMANCE SUMMARY\")\n",
    "logger.info(\"===================================\")\n",
    "logger.info(f\"‚úÖ Accuracy         : {final_acc*100:.2f}%\")\n",
    "logger.info(f\"üéØ Precision (Macro): {final_prec:.4f}\")\n",
    "logger.info(f\"üìå Recall    (Macro): {final_rec:.4f}\")\n",
    "logger.info(f\"üìà F1-Score  (Macro): {final_f1:.4f}\")\n",
    "\n",
    "logger.info(\"\\nüèÜ BEST EPOCH METRICS\")\n",
    "logger.info(\"===================================\")\n",
    "logger.info(f\"üìå Highest Test Accuracy : {best_acc*100:.2f}% at Epoch {best_acc_epoch}\")\n",
    "logger.info(f\"üìå Highest Test F1-Score : {best_f1:.4f} at Epoch {best_f1_epoch}\")\n",
    "\n",
    "# =====================\n",
    "# CONFUSION MATRIX\n",
    "# =====================\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=test_dataset.classes,\n",
    "            yticklabels=test_dataset.classes,\n",
    "            cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# =====================\n",
    "# TRAINING CURVES\n",
    "# =====================\n",
    "plt.figure()\n",
    "plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "plt.plot(test_loss_list, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_acc_list, label=\"Train Accuracy\")\n",
    "plt.plot(test_acc_list, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f1_list, label=\"Test F1 Score (Macro)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
